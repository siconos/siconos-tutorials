{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un exemple d'utilisation d'hdf5 en python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebooks\n",
    "\n",
    "Un \"notebook\" est une feuille de travail interactive, dans laquelle vous allez pouvoir exécuter des\n",
    "commandes, décrite dans \"cases\", les cellules.\n",
    "\n",
    "Plusieurs environnements sont disponibles (menu kernel ci-dessus -->change kernel). On travaillera ici avec Python3.\n",
    "\n",
    "Dans notre cas, chaque cellule pourra contenir soit du code python, soit des commentaires, du texte en markdown.\n",
    "\n",
    "Voici un résumé des principaux raccourcis:\n",
    "\n",
    "* Editer une cellule : Enter\n",
    "* Exécuter le contenu d'une cellule : Shift + Enter\n",
    "* Exécuter toutes les cellules : menu kernel (haut de la page) --> Run all\n",
    "* Effacer une cellule : DD\n",
    "* Ajouter une cellule : Ctrl-mb\n",
    "* Afficher les raccourcis : Ctrl-m h\n",
    "* Liste des \"magic commands\" python : exécuter %lsmagic dans une cellule\n",
    "\n",
    "Plus d'infos :  https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html#references\n",
    "\n",
    "Attention: chaque cellule peut-être exécutée indépendamment des autres mais les résultats d'exécution sont conservées.\n",
    "Pour repartir de zero il faut soit faire appel à \"%reset\" ou à restart dans le menu kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import du package hdf5\n",
    "\n",
    "Pour utiliser hdf5 en python, nous aurons besoin du package h5py.\n",
    "\n",
    "Nous aurons également besoin de numpy qui est le package standard de calcul scientifique en python, http://www.numpy.org.\n",
    "\n",
    "Nous l'utiliserons pour manipuler des matrices et des vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour obtenir des infos sur un package ou une fonction, il suffit d'utiliser\n",
    "\"?\", et la doc apparait en bas du navigateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de cette démo/TP est d'illustrer les concepts de base d'hdf5, à travers la création d'un exemple simple.\n",
    "Nous allons sauvegarder dans un fichier hdf5 des champs scalaires représentant certaines grandeurs physiques sur une grille 3D (sous forme de tableau numpy), puis les visualiser, les relire etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition des variables\n",
    "\n",
    "Pour commencer, on crée un tableau 3D de dimension Nx X Ny X Nz, rempli aléatoirement, grâce à numpy (np)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolution du champ\n",
    "Nx = Ny = Nz = 256\n",
    "resolution = (Nx, Ny, Nz)\n",
    "\n",
    "# Deux champs scalaires, initialisés aléatoirement\n",
    "vx = np.random.random_sample(resolution)\n",
    "temperature = np.random.random_sample(resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans numpy, l'accès aux valeurs du tableau se fait comme suit \n",
    "\n",
    "(pour plus de détails voir un des nombreux tuto disponibles en ligne, par exemple,\n",
    "https://docs.scipy.org/doc/numpy-dev/user/quickstart.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6716746851776874\n",
      "[0.71640469 0.50838259 0.81869901 0.86250276 0.58697174 0.25576814]\n",
      "[[0.81869901 0.86250276]\n",
      " [0.02303176 0.67167469]]\n"
     ]
    }
   ],
   "source": [
    "# un exemple de manipulation de tableau ...\n",
    "small_tab = np.random.random((4,6))\n",
    "# un élement:\n",
    "print(small_tab[3, 3])\n",
    "# une \"ligne\"\n",
    "print(small_tab[2, :])\n",
    "# une sous-partie du tableau:   \n",
    "print(small_tab[2:4, 2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Le \"fichier\" hdf5\n",
    "\n",
    "Le \"fichier\" hdf5 est l'objet principal qui permettra de stocker vos données et leurs attributs. On parlera à la fois\n",
    "de \"fichier\" pour le fichier sur le disque (extension .h5, .hdf5 ou .he5) et pour l'objet manipulé dans le code.\n",
    "\n",
    "Il s'agit d'une sorte de container de **datasets** (les structures de données, voir plus bas) qui peut également être organisé en **groupes** et sous-groupes. \n",
    "\n",
    "**TP** - *Créez un \"fichier\" hdf5 en mode 'écriture'. Il faudra pour cela faire appel à la fonction\n",
    "h5py.File*\n",
    "\n",
    "Rappel : pour accèder à la doc, il suffit de taper\n",
    "?h5py.NOM_FONCTION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la documentation de la fonction\n",
    "?h5py.File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'demo_v0.h5'\n",
    "# Création/ouverture en mode 'ecriture'\n",
    "mode = 'w'\n",
    "hdf_file = h5py.File(filename, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand toutes les données auront été sauvegardées, il sera nécessaire de fermer le fichier, pour\n",
    "valider l'écriture sur le disque, via la fonction close()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Vérifiez que le fichier a bien été créé. Notez au passage que dans ipython notebook vous avez accès à certaines commandes du terminal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 120\n",
      "-rw-r--r--@  1 Franck  staff   6148  5 fév  2018 .DS_Store\n",
      "-rw-r--r--   1 Franck  staff   2882  5 fév  2018 demo_hdf5.py\n",
      "-rw-r--r--   1 Franck  staff   4404  5 fév  2018 xdmf.py\n",
      "-rw-r--r--   1 Franck  staff    847  6 fév  2018 demo_io.cxx\n",
      "-rw-r--r--   1 Franck  staff    720  6 fév  2018 demo_io.py\n",
      "-rw-r--r--   1 Franck  staff  18241 11 fév 17:08 demo_hdf5.ipynb\n",
      "-rw-r--r--   1 Franck  staff   5384 11 fév 17:08 tp_part1.ipynb\n",
      "drwxr-xr-x  22 Franck  staff    704 20 fév 15:41 \u001b[34m..\u001b[m\u001b[m/\n",
      "drwxr-xr-x   3 Franck  staff     96 15 mar 14:58 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m/\n",
      "drwxr-xr-x  11 Franck  staff    352 28 mar 10:25 \u001b[34m.\u001b[m\u001b[m/\n",
      "-rw-r--r--   1 Franck  staff     96 28 mar 10:25 demo_v0.h5\n"
     ]
    }
   ],
   "source": [
    "ls -altr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la mesure ou h5py.File est une classe, on peut avoir accès à ses attributs et méthodes.\n",
    "\n",
    "Dans le notebook il suffit d'utiliser la complétion pour avoir une liste complète des attributs:\n",
    "\n",
    "nom_class. + TAB\n",
    "\n",
    "*Affichage du nom du fichier sur le disque et le nom de l'objet file:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "demo_v0.h5\n"
     ]
    }
   ],
   "source": [
    "print(hdf_file.name)\n",
    "print(hdf_file.filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de datasets: des tableaux dans le fichiers hdf5\n",
    "\n",
    "Dans un fichier hdf, les \"données\" sont stockées sous forme de dataset.\n",
    "Un dataset est un tableau multi-dimensionnel contenant des données d'un même type.\n",
    "\n",
    "**TP** *Créez deux datasets dans le fichier hdf5, pour stocker les deux champs scalaires définis plus haut:*\n",
    "\n",
    "* *un dataset 'data_velo' vide et de même résolution que vx*\n",
    "* *un dataset 'data_tp' qui contient une copie de temperature*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Represents an HDF5 dataset\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Create a new Dataset object by binding to a low-level DatasetID.\n",
       "        \n",
       "\u001b[0;31mFile:\u001b[0m           /anaconda3/lib/python3.7/site-packages/h5py/_hl/dataset.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Création de dataset : \n",
    "?h5py.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres : nom, shape, type\n",
    "data_velo = hdf_file.create_dataset('velocity', resolution, dtype=np.float64)\n",
    "# Paramètres : un tableau numpy\n",
    "data_tp = hdf_file.create_dataset('temperature', data=temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation des datasets\n",
    "\n",
    "Les datasets peuvent être manipulés comme des tableaux numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"temperature\": shape (256, 256, 256), type \"<f8\">\n",
      "<HDF5 dataset \"velocity\": shape (256, 256, 256), type \"<f8\">\n",
      "(256, 256, 256)\n",
      "True\n",
      "0.5643377532174662\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(data_tp)\n",
    "print(data_velo)\n",
    "print(data_tp.shape)\n",
    "# A ce stade, data_tp contient les mêmes valeurs que temperature tandis que tous les éléments de data_velo sont nuls.\n",
    "print(np.allclose(data_tp, temperature))\n",
    "print(temperature[1,5,3])\n",
    "print(data_velo[1:10, 1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ou par l'intermédiaire du fichier hdf5, via leur nom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"velocity\": shape (256, 256, 256), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "print(hdf_file['velocity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La modification du contenu de chaque dataset est similaire à celle d'un tableau numpy.\n",
    "Nous allons maintenant remplir data_velo en calculant le cosinus de vx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_velo[...] = np.cos(vx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les groupes\n",
    "\n",
    "Il est donc possible de l'organiser en groupes et sous-groupes contenant des datasets, via la fonction\n",
    "create_group.\n",
    "\n",
    "**TP ** *Créez un groupe 'champs' et un groupe 'infos' contenant un sous-groupe  'diverses'.*\n",
    "\n",
    "Remarque: l'objet fichier hdf5 possède a une structure arborescente, à la manière d'un système de fichier classique.\n",
    "Nous avons vu plus haut que le nom de l'objet hdf_file est '/'. Cela se traduit également dans la manière de nommer les groupes. le groupe 'diverses' apparaitra ainsi:\n",
    "\n",
    "/infos/diverses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Create and return a new subgroup.\n",
       "\n",
       "Name may be absolute or relative.  Fails if the target name already\n",
       "exists.\n",
       "\n",
       "track_order\n",
       "    Track dataset/group/attribute creation order under this group\n",
       "    if True. If None use global default h5.get_config().track_order.\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/lib/python3.7/site-packages/h5py/_hl/group.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?h5py.File.create_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/infos/diverses\" (0 members)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation d'un groupe 'champs'\n",
    "g1 = hdf_file.create_group('champs')\n",
    "# Puis d'un groupe infos/diverses\n",
    "hdf_file.create_group('/infos/diverses/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accès aux données et attributs se fait de manière classique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 group \"/champs\" (0 members)>\n",
      "<HDF5 group \"/infos\" (1 members)>\n"
     ]
    }
   ],
   "source": [
    "print(hdf_file['champs'])\n",
    "print(hdf_file['infos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sommes maintenant en mesure de créer un dataset dans le groupe champs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"density\": shape (256, 256, 256), type \"<f8\">"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.create_dataset('density', resolution, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut balayer tous les éléments du groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('champs', <HDF5 group \"/champs\" (1 members)>)\n",
      "('infos', <HDF5 group \"/infos\" (1 members)>)\n",
      "('temperature', <HDF5 dataset \"temperature\": shape (256, 256, 256), type \"<f8\">)\n",
      "('velocity', <HDF5 dataset \"velocity\": shape (256, 256, 256), type \"<f8\">)\n",
      "groupe champs ...\n",
      "('density', <HDF5 dataset \"density\": shape (256, 256, 256), type \"<f8\">)\n"
     ]
    }
   ],
   "source": [
    "for it in hdf_file.items():\n",
    "    print(it)\n",
    "for it in hdf_file['champs'].items():\n",
    "    print(\"groupe champs ...\")\n",
    "    print(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou également supprimer un groupe avec la fonction python del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hdf_file['/infos/diverses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"density\": shape (256, 256, 256), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "print(g1['density'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributs\n",
    "\n",
    "Un autre intérêt du format hdf5 est de pouvoir associer aux datasets et groupes des méta-données, i.e. des informations sous formes d'attributs.\n",
    "\n",
    "Voici quelques exemples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_file['velocity'].attrs['année'] = 2015\n",
    "hdf_file['velocity'].attrs['commentaires'] = 'Valeurs experimentales du champs de vitesse'\n",
    "g1['density'].attrs['description'] = u\"une description du champs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis afficher les caractéristiques d'un dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "Valeurs experimentales du champs de vitesse\n"
     ]
    }
   ],
   "source": [
    "for it in hdf_file['velocity'].attrs.values():\n",
    "    print(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecriture et fermeture du fichier :\n",
    "\n",
    "Nous sommes maintenant en mesure de fermer le fichier.\n",
    "\n",
    "La visualisation des données peut se faire par différentes méthodes:\n",
    "\n",
    "* h5dump\n",
    "* hdfview\n",
    "* un logiciel capable de lire du hdf5 (visit ...)\n",
    "\n",
    "\n",
    "**TD** *Visualisez le contenu du fichier avec hdfview et hdfdump, dans votre terminal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant repartir de zero et charger des données d'un fichier hdf5\n",
    "\n",
    "## Lecture d'un fichier hdf5\n",
    "\n",
    "**TP** *Créez un tableau 'new_field' à partir du champs temperature du fichier hdf5 'demo_v0.h5'*\n",
    "\n",
    "* ouvrir le fichier demo_v0.h5\n",
    "* créer le tableau numpy à partir du dataset temperature\n",
    "\n",
    "Notes : \n",
    "* la lecture se fait simplement en créant un objet fichier en mode 'lecture'\n",
    "* il faudra utiliser la fonction np.asarray pour assurer la conversion du dataset vers le tableau numpy\n",
    " \n",
    " tab_numpy = np.asarray(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remise à zero de l'environnement ...\n",
    "%reset\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du fichier hdf5\n",
    "filename = 'demo_v0.h5'\n",
    "in_file = h5py.File(filename, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage du contenu du fichier ...\n",
    "\n",
    "Notez au passage l'intérêt du format hdf5 : le fichier est 'auto-suffisant': toutes les informations\n",
    "nécessaires à la comprehension de son contenu sont disponibles (noms des variables, dimensions des tableaux ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On balaies tout le contenu du fichier (datasets et groupes)\n",
    "for keys in in_file:\n",
    "    print(keys, in_file[keys])\n",
    "    # Dans chaque cas, on affiche la liste des attributs\n",
    "    for it in in_file[keys].attrs.items():\n",
    "        print('-->', it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un nouveau tableau\n",
    "new_field = np.asarray(in_file['velocity'])\n",
    "print(new_field[1:10, 1:10, 3])\n",
    "print(new_field.shape)\n",
    "print(new_field.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne pas oublier de fermer le fichier!\n",
    "in_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(new_field[1:100, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un exemple d'utilisation de XDMF et HDF5\n",
    "\n",
    "Paraview n'est (malheureusement) pas capable de lire directement du hdf5.\n",
    "Il faut le convertir en xmf. Nous vous proposons ici un exemple avec une fonction python capable de\n",
    "faire cette conversion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On recupère la fonction permettant d'écrire l'entête xdmf\n",
    "from xdmf import XDMFWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cette fonction est un exemple de génération de la partie 'ASCII' du fichier xdmf, en fonction de la  géométrie du domaine et de la grille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(XDMFWriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description du domaine, de la grille\n",
    "origin = [0.,] * 3\n",
    "space_step = [0.1,] * 3\n",
    "resolution = new_field.shape\n",
    "filename = 'demo_v0.h5'\n",
    "wr = XDMFWriter(filename, 3, resolution, origin, space_step, ['velocity', 'temperature'], 1, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Le fichier peut maintenant être lu par Paraview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
